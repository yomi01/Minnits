#!/usr/bin/env python3
"""
Test script for the model switching functionality.
"""

import json
import sys
import os

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from summarization.summarizer import ConversationSummarizer
from ui.app import get_available_ollama_models, get_model_info

def test_model_switching():
    """Test the model switching and validation functionality"""
    
    print("üß™ Testing Model Switching Functionality")
    print("=" * 60)
    
    # Test getting available models
    print("1. Testing model discovery...")
    try:
        models = get_available_ollama_models()
        if models:
            print(f"‚úÖ Found {len(models)} available models:")
            for model in models[:5]:  # Show first 5
                print(f"   ‚Ä¢ {model}")
            if len(models) > 5:
                print(f"   ... and {len(models) - 5} more")
        else:
            print("‚ö†Ô∏è No models found. Make sure Ollama is running with models installed.")
            return False
    except Exception as e:
        print(f"‚ùå Error getting models: {e}")
        return False
    
    # Test model info retrieval
    if models:
        test_model = models[0]
        print(f"\n2. Testing model info for '{test_model}'...")
        try:
            model_info = get_model_info(test_model)
            if model_info:
                print("‚úÖ Model info retrieved:")
                print(f"   ‚Ä¢ Size: {model_info['size']}")
                print(f"   ‚Ä¢ Family: {model_info['family']}")
                print(f"   ‚Ä¢ Format: {model_info['format']}")
            else:
                print("‚ö†Ô∏è Could not retrieve model info")
        except Exception as e:
            print(f"‚ùå Error getting model info: {e}")
    
    # Test model switching with summarizer
    print(f"\n3. Testing model switching in summarizer...")
    
    # Sample transcript for testing
    sample_transcript = {
        "transcript": "Quick test conversation for model switching.",
        "segments": [
            {"timestamp": "00:00:00", "text": "Hello, this is a test.", "speaker": "Speaker 1"},
            {"timestamp": "00:00:02", "text": "Yes, we are testing model switching.", "speaker": "Speaker 2"},
            {"timestamp": "00:00:04", "text": "The model should work correctly.", "speaker": "Speaker 1"}
        ]
    }
    
    # Test with first available model
    if models:
        try:
            print(f"   Testing with model: {models[0]}")
            summarizer1 = ConversationSummarizer(ollama_model=models[0])
            
            # Try a quick summarization
            summary1 = summarizer1.summarize(sample_transcript, use_detailed_format=False)
            print(f"‚úÖ Model '{models[0]}' working correctly")
            
            # Test with second model if available
            if len(models) > 1:
                print(f"   Testing with model: {models[1]}")
                summarizer2 = ConversationSummarizer(ollama_model=models[1])
                summary2 = summarizer2.summarize(sample_transcript, use_detailed_format=False)
                print(f"‚úÖ Model '{models[1]}' working correctly")
                
                # Compare results
                if summary1.get("summary") != summary2.get("summary"):
                    print("‚úÖ Different models produce different outputs (as expected)")
                else:
                    print("‚ÑπÔ∏è Models produced similar outputs")
            
        except Exception as e:
            print(f"‚ùå Error testing models: {e}")
            return False
    
    # Test invalid model handling
    print("\n4. Testing invalid model handling...")
    try:
        invalid_summarizer = ConversationSummarizer(ollama_model="nonexistent-model:999b")
        print("‚ùå Should have failed with invalid model")
        return False
    except Exception as e:
        print("‚úÖ Invalid model correctly rejected")
    
    print("\nüéâ All model switching tests completed successfully!")
    print("\nModel switching features:")
    print("  ‚Ä¢ ‚úÖ Model discovery from Ollama")
    print("  ‚Ä¢ ‚úÖ Model information retrieval")
    print("  ‚Ä¢ ‚úÖ Dynamic model switching")
    print("  ‚Ä¢ ‚úÖ Invalid model validation")
    print("  ‚Ä¢ ‚úÖ UI integration ready")
    
    return True

def show_model_recommendations():
    """Show model recommendations for different use cases"""
    print("\nüìã Model Recommendations by Use Case:")
    print("-" * 40)
    
    recommendations = {
        "üíº Business Meetings": [
            "gemma3:12b - Excellent for formal meeting minutes",
            "llama3.2:8b - Good balance of speed and quality",
            "qwen2.5:7b - Strong multilingual support"
        ],
        "üéì Academic/Research": [
            "llama3.2:8b - Great for technical content",
            "mistral:7b - Good for analysis and summaries",
            "gemma3:12b - Excellent comprehension"
        ],
        "‚ö° Quick Summaries": [
            "llama3.2:3b - Fast processing",
            "gemma3:3b - Good quality, small size",
            "phi3:3.8b - Efficient for simple tasks"
        ],
        "üåç Multilingual": [
            "qwen2.5:7b - Best for Chinese/English",
            "gemma3:12b - Good multilingual support",
            "mistral:7b - European languages"
        ]
    }
    
    for category, models in recommendations.items():
        print(f"\n{category}:")
        for model in models:
            print(f"  ‚Ä¢ {model}")

if __name__ == "__main__":
    success = test_model_switching()
    
    if success:
        show_model_recommendations()
    
    sys.exit(0 if success else 1) 